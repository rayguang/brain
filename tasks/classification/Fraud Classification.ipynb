{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported Libraries\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "\n",
    "# Classifier Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import collections\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Other Libraries\n",
    "#from imblearn.datasets import fetch_datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"fraud_prep.csv\")\n",
    "\n",
    "# First 5 features\n",
    "df.head()\n",
    "\n",
    "# Dataset features\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class types: 0 non-fraud, 1 fraud\n",
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n",
      "Ratio of class types: 0 non-fraud, 1 fraud\n",
      "0    0.998273\n",
      "1    0.001727\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# count the occurrences of fraud and no fraud cases\n",
    "print(\"Class types: 0 non-fraud, 1 fraud\")\n",
    "print(df[\"Class\"].value_counts())\n",
    "\n",
    "# Normalize target for training\n",
    "print(\"Ratio of class types: 0 non-fraud, 1 fraud\")\n",
    "print(df[\"Class\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any missing value\n",
    "df.isnull().sum()\n",
    "\n",
    "# Conclusion: no null value, i.e., no need to fill/drop NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset SUMMARY: very in-balanced classes, i.e., many non-fraud and a few fraud classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of fraud transaction analysis\n",
    "In banking or credit payment industry, the standard way is to use statistical approach to identify an \"optimal\" statistics threshold to separate fraud transactions and non-fraud transactions. \n",
    "\n",
    "A common used approach to find such threhold is to find the mean of the sample transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94838.202258</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>-0.006271</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>-0.007860</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000644</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>88.291022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80746.806911</td>\n",
       "      <td>-4.771948</td>\n",
       "      <td>3.623778</td>\n",
       "      <td>-7.033281</td>\n",
       "      <td>4.542029</td>\n",
       "      <td>-3.151225</td>\n",
       "      <td>-1.397737</td>\n",
       "      <td>-5.568731</td>\n",
       "      <td>0.570636</td>\n",
       "      <td>-2.581123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372319</td>\n",
       "      <td>0.713588</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>-0.040308</td>\n",
       "      <td>-0.105130</td>\n",
       "      <td>0.041449</td>\n",
       "      <td>0.051648</td>\n",
       "      <td>0.170575</td>\n",
       "      <td>0.075667</td>\n",
       "      <td>122.211321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time        V1        V2        V3        V4        V5  \\\n",
       "Class                                                                   \n",
       "0      94838.202258  0.008258 -0.006271  0.012171 -0.007860  0.005453   \n",
       "1      80746.806911 -4.771948  3.623778 -7.033281  4.542029 -3.151225   \n",
       "\n",
       "             V6        V7        V8        V9     ...           V20       V21  \\\n",
       "Class                                             ...                           \n",
       "0      0.002419  0.009637 -0.000987  0.004467     ...     -0.000644 -0.001235   \n",
       "1     -1.397737 -5.568731  0.570636 -2.581123     ...      0.372319  0.713588   \n",
       "\n",
       "            V22       V23       V24       V25       V26       V27       V28  \\\n",
       "Class                                                                         \n",
       "0     -0.000024  0.000070  0.000182 -0.000072 -0.000089 -0.000295 -0.000131   \n",
       "1      0.014049 -0.040308 -0.105130  0.041449  0.051648  0.170575  0.075667   \n",
       "\n",
       "           Amount  \n",
       "Class              \n",
       "0       88.291022  \n",
       "1      122.211321  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean of features for each class group\n",
    "df.groupby('Class').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Fraud_actual vs Fraud_flagged ****\n",
      "Fraud_flagged       0     1\n",
      "Fraud_actual               \n",
      "0              278946  5369\n",
      "1                 316   176\n",
      "**** Fraud_actual vs Fraud_flagged (%) ****\n",
      "Fraud_flagged          0          1\n",
      "Fraud_actual                       \n",
      "0              98.111602   1.888398\n",
      "1              64.227642  35.772358\n"
     ]
    }
   ],
   "source": [
    "# Now use V1 < -3 and V2 > 2 as threshold to identify the fraud transactions\n",
    "df['fraud_flagged'] = np.where(np.logical_and(df['V1']<-3, df['V2']>2), 1,0)\n",
    "ct=pd.crosstab(df.Class, df.fraud_flagged, rownames=[\"Fraud_actual\"], colnames=[\"Fraud_flagged\"])\n",
    "\n",
    "print(\"**** Fraud_actual vs Fraud_flagged ****\")\n",
    "print(ct)\n",
    "\n",
    "print(\"**** Fraud_actual vs Fraud_flagged (%) ****\")\n",
    "print(ct.apply(lambda r: r/r.sum()*100, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SUMMARY: 35.77% fraud transactions are identified, however, 64.22% are not identified. 1.88% non-fraud transactions are flagged as fraud.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns/features\n",
    "X = df.drop([\"Time\", \"Class\", \"fraud_flagged\"], axis=1)\n",
    "y = df[\"Class\"]\n",
    "\n",
    "# Create training and test sets using random split\n",
    "# Note that, we can also use CV, shuffle\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model\n",
    "clf = LogisticRegression(solver=\"liblinear\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.999283727985169\n"
     ]
    }
   ],
   "source": [
    "# Get prediction on test set\n",
    "prediction  = clf.predict(X_test)\n",
    "proba       = clf.predict_proba(X_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC score: 0.9741287058139425\n",
      "\n",
      "Stats report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71082\n",
      "           1       0.88      0.67      0.76       120\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.94      0.83      0.88     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[71071    11]\n",
      " [   40    80]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print ROC and Confusion Matrix\n",
    "# print the ROC score\n",
    "print(\"ROC score: {}\\n\".format(roc_auc_score(y_test, proba[:,1])))\n",
    "\n",
    "print(\"Stats report:\\n{}\\n\".format(classification_report(y_test, prediction)))\n",
    "\n",
    "# print confusion matrix\n",
    "cfm = confusion_matrix(y_true=y_test, y_pred=prediction)\n",
    "print(\"Confusion matrix:\\n{}\\n\".format(cfm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "\n",
    "* The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "* The F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.The F-beta score weights recall more than precision by a factor of beta. beta == 1.0 means recall and precision are equally important.\n",
    "\n",
    "* The support is the number of occurrences of each class in y_true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the confusion matrix\n",
    "sns.heatmap(cfm, annot=True, annot_kws={\"size\":12}, fmt=\"d\", cbar=False, linewidths=0.1, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "plt.ylabel(\"Actual\", fontsize=10)\n",
    "plt.xlabel(\"Prediction\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: 40 false negatives, 11 false positives, 80 out of 120 (67%)  fraud are flagged. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Resampling\n",
    "As shown above, the dataset is highly inbalanced. With a more balanced dataset, let us test if we can improve the performance.\n",
    "\n",
    "We can either undersampling non-fraud cases (losing data) or oversampling fraud cases (duplicates). \n",
    "\n",
    "SMOTE (oversampling method) is used to create synthetic data. Instead of copying duplicated data, SMOTE uses nearest neighbor characteristics to create synthetic fraud cases. SMOTE works well when the fraud cases nearest neighbors show distinct characteristics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before resampling:\n",
      "0    213233\n",
      "1       372\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "After resampling:\n",
      "1    213233\n",
      "0    213233\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the resampling method\n",
    "resample_method = SMOTE()\n",
    "X_resampled, y_resampled = resample_method.fit_sample(X_train, y_train)\n",
    "\n",
    "# check before and after resample\n",
    "print(\"Before resampling:\\n{}\\n\".format(y_train.value_counts()))\n",
    "print(\"After resampling:\\n{}\\n\".format(pd.Series(y_resampled).value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with resampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9830763180809527\n",
      "ROC score (resampled): 0.9763196027123604\n",
      "\n",
      "Stats report (resampled):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     71082\n",
      "           1       0.08      0.89      0.15       120\n",
      "\n",
      "    accuracy                           0.98     71202\n",
      "   macro avg       0.54      0.94      0.57     71202\n",
      "weighted avg       1.00      0.98      0.99     71202\n",
      "\n",
      "\n",
      "Confusion matrix (resampled):\n",
      "[[69890  1192]\n",
      " [   13   107]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "clf = LogisticRegression(solver=\"liblinear\")\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get prediction on test set\n",
    "prediction  = clf.predict(X_test)\n",
    "prob       = clf.predict_proba(X_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_test,prediction))\n",
    "\n",
    "# Print ROC and Confusion Matrix\n",
    "# print the ROC score\n",
    "print(\"ROC score (resampled): {}\\n\".format(roc_auc_score(y_test, prob[:,1])))\n",
    "\n",
    "print(\"Stats report (resampled):\\n{}\\n\".format(classification_report(y_test, prediction)))\n",
    "\n",
    "# print confusion matrix\n",
    "cfm = confusion_matrix(y_true=y_test, y_pred=prediction)\n",
    "print(\"Confusion matrix (resampled):\\n{}\\n\".format(cfm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SUMMARY: 106 out of 120 fraud transactions are flagged. However, we have an increase false positive 11 -> 1190, meaning more non-fraud transactions flagged as fraud. This is likely because the fraud case scattered over the dataset and introduced some noise, i.e., nearest neighbors not necessarily are fraud transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "# ADD COMMENTS\n",
    "Random forest has a built-in mode to deal with inbalanced dataset. The balanced* mode adjusts weights inversely proportional to the class frequence in the input data as num_samples/(np.bincount(y) * num_classes)\n",
    "\n",
    "The \"balanced\" mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Random Forest with normal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9995084407741356\n",
      "\n",
      "ROC score = 0.9206149822270993\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71082\n",
      "           1       0.95      0.75      0.84       120\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.97      0.87      0.92     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[71077     5]\n",
      " [   30    90]]\n",
      "\n",
      "CPU times: user 9.55 s, sys: 126 ms, total: 9.67 s\n",
      "Wall time: 9.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define the model as the random forest\n",
    "clf = RandomForestClassifier(class_weight=\"balanced_subsample\", random_state=0)\n",
    "\n",
    "# fit the model to our training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# obtain predictions from the test data \n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "# predict probabilities\n",
    "prob = clf.predict_proba(X_test)\n",
    "\n",
    "# print the accuracy score, ROC score, classification report and confusion matrix\n",
    "print(\"Accuracy Score: {}\\n\".format(accuracy_score(y_test, prediction)))\n",
    "print(\"ROC score = {}\\n\".format(roc_auc_score(y_test, prob[:,1])))\n",
    "print(\"Classification Report:\\n{}\\n\".format(classification_report(y_test, prediction)))\n",
    "print(\"Confusion Matrix:\\n{}\\n\".format(confusion_matrix(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Random Forest with Resampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9995505744220669\n",
      "ROC score (resampled): 0.9523132907534021\n",
      "\n",
      "Stats report (resampled):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71082\n",
      "           1       0.89      0.84      0.86       120\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.94      0.92      0.93     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "\n",
      "Confusion matrix (resampled):\n",
      "[[71069    13]\n",
      " [   19   101]]\n",
      "\n",
      "CPU times: user 32.2 s, sys: 245 ms, total: 32.4 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training model\n",
    "# The \"balanced\" mode uses the values of y to automatically adjust weights \n",
    "# inversely proportional to class frequencies in the input data as \n",
    "# n_samples / (n_classes * np.bincount(y)).\n",
    "clf = RandomForestClassifier(class_weight=\"balanced_subsample\", random_state=0)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get prediction on test set\n",
    "prediction  = clf.predict(X_test)\n",
    "prob       = clf.predict_proba(X_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_test,prediction))\n",
    "\n",
    "# Print ROC and Confusion Matrix\n",
    "# print the ROC score\n",
    "print(\"ROC score (resampled): {}\\n\".format(roc_auc_score(y_test, prob[:,1])))\n",
    "\n",
    "print(\"Stats report (resampled):\\n{}\\n\".format(classification_report(y_test, prediction)))\n",
    "\n",
    "# print confusion matrix\n",
    "cfm = confusion_matrix(y_true=y_test, y_pred=prediction)\n",
    "print(\"Confusion matrix (resampled):\\n{}\\n\".format(cfm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SUMMARY:  for resampled dataset, RandomeForest shows similar true positives to LogisticRegression102 (RF) vs 120(LR). RandomForest  does not misclassify as many as non-fraud cases as fraud 16 (RF) vs 1190 (LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV for optimal parameters\n",
    "For the classifier parameters, so far default values are mostly applied. We can manually set which scores carry more importance using GridSearchCV to find the optimal params. For fraud detection, we would rather prefer a better recall score (i.e., detect as many as fraud cases at cost of misclassifying non-fraud to fraud). We can also ajust F-score to reduce false positives (i.e., improved precision). \n",
    "\n",
    "Goal is to find optimal recall-precision balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define the parameter sets to test\n",
    "param_grid = {\"n_estimators\": [10, 50], \n",
    "              \"max_features\": [\"auto\", \"log2\"],  \n",
    "#               \"min_samples_leaf\": [1, 10],\n",
    "              \"max_depth\": [4, 8], \n",
    "              \"criterion\": [\"gini\", \"entropy\"], \n",
    "              \"class_weight\": [None, {0:1, 1:12}]\n",
    "}\n",
    "\n",
    "# define the model to use\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# combine the parameter sets with the defined model\n",
    "CV_model = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=\"recall\", n_jobs=-1)\n",
    "\n",
    "# fit the model to our training data and obtain best parameters\n",
    "CV_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "parameters = {'n_estimators': [4, 6, 9], \n",
    "              'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10], \n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the clf to the best combination of parameters\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# predict probabilities\n",
    "probs = CV_model.predict_proba(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "# print the accuracy score, ROC score, classification report and confusion matrix\n",
    "print(\"Accuracy Score: {}\\n\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"ROC score = {}\\n\".format(roc_auc_score(y_test, probs[:,1])))\n",
    "print(\"Classification Report:\\n{}\\n\".format(classification_report(y_test, predictions)))\n",
    "print(\"Confusion Matrix:\\n{}\\n\".format(confusion_matrix(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "Decision tree tends to overfit on data with large number of features. We can apply feature selection or PCA/ICA beforehand to find discriminative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced mode used\n",
    "clf = DecisionTreeClassifier()\n",
    "print(cfl.get_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
