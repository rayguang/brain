{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: training, validation and test \n",
    "k-fold CV (cross-validation) is used to reduce the risk of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process dataset\n",
    "crime_prep.csv contains many missing data in column 2 (county) and 3 (community). \n",
    "For missing data:\n",
    "1) if it is missing at random, we can drop the data;\n",
    "2) if it is missing not at random (e.g., depend on other variables), we can use imputation to reduce bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.05208706855773926 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df_prep = pd.read_csv('crime_prep.csv')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#df_prep.shape\n",
    "\n",
    "# Remove non predictive attributes, such as state, county, community, communitynames, fold\n",
    "df_prep = df_prep.drop(['v_cont_0', 'v_cat_0', 'v_cat_1', 'v_cat_2', 'v_cat_3'], axis=1)\n",
    "\n",
    "# Use impute function to fill the missing values (NaN)\n",
    "# Missing value is filled with mean of the column data\n",
    "df_impute = df_prep.copy()\n",
    "impute = Imputer(missing_values=\"NaN\", strategy='mean', axis=0)\n",
    "\n",
    "# Fit the dataframe into imputer\n",
    "impute = impute.fit(df_prep)\n",
    "# Fit the new values into df and transformed\n",
    "df_prep = impute.transform(df_impute)\n",
    "\n",
    "# Convert to dataframe and add columns\n",
    "df = pd.DataFrame(df_prep)\n",
    "df.columns = df_impute.columns \n",
    "#df\n",
    "\n",
    "# Build features and target dataframe\n",
    "features = df.drop([\"target\"], axis=1)\n",
    "target = pd.DataFrame(df, columns=[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score:  [0.34237567 0.19621919 0.33110611 0.20768963 0.22935667 0.35320383\n",
      " 0.3367789  0.08079969 0.2004463  0.23229297]\n",
      "Accuracy: 0.25(+/- 0.17)\n",
      "           Importance\n",
      "v_cont_55    0.423790\n",
      "v_cont_49    0.078133\n",
      "v_cont_48    0.056849\n",
      "v_cont_8     0.031982\n",
      "v_cont_95    0.021413\n"
     ]
    }
   ],
   "source": [
    "DT = tree.DecisionTreeRegressor()\n",
    "DT = DT.fit(features, target)\n",
    "\n",
    "DT_predict = DT.predict(features)\n",
    "scores = cross_val_score(DT, features, target, cv=10)\n",
    "print(\"cross validation score: \", scores)\n",
    "print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores.mean(), scores.std()*2))\n",
    "\n",
    "KEEP_FEATURES = 5\n",
    "#features_new = zip(features.columns, (SelectKBest(f_regression, k=5).fit_transform(features, target)))\n",
    "importantFeatures = sorted(zip(features.columns, DT.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# fit, we can choose f_regression OR mutual_info_regression, we can test both and see the result\n",
    "importantFeatures[:KEEP_FEATURES]\n",
    "df_DT=pd.DataFrame(DT.feature_importances_, columns = [\"Importance\"], index = features.columns).sort_values(['Importance'], ascending = False)[:KEEP_FEATURES]\n",
    "print(df_DT)\n",
    "# plt.figure()\n",
    "# df_DT.plot.bar()\n",
    "# plt.xlabel('Top '+str(KEEP_FEATURES)+' Predictive Features')\n",
    "# plt.ylabel('Feature Coefficients')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3 43 44 45 50]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_names</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>v_cont_49</td>\n",
       "      <td>2388.618688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>v_cont_55</td>\n",
       "      <td>2381.983200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>v_cont_48</td>\n",
       "      <td>1987.057310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v_cont_8</td>\n",
       "      <td>1758.772273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>v_cont_50</td>\n",
       "      <td>1588.379860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_names       scores\n",
       "44     v_cont_49  2388.618688\n",
       "50     v_cont_55  2381.983200\n",
       "43     v_cont_48  1987.057310\n",
       "3       v_cont_8  1758.772273\n",
       "45     v_cont_50  1588.379860"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_prep = pd.read_csv(\"./crime_prep.csv\")\n",
    "# df_prep = df_prep.drop(['v_cont_0', 'v_cat_0', 'v_cat_1', 'v_cat_2', 'v_cat_3'], axis=1)\n",
    "# df_impute = df_prep.copy()\n",
    "# impute = Imputer(missing_values=\"NaN\", strategy='mean', axis=0)\n",
    "\n",
    "# # Fit the dataframe into imputer\n",
    "# impute = impute.fit(df_prep)\n",
    "# # Fit the new values into df and transformed\n",
    "# df_prep = impute.transform(df_impute)\n",
    "# df = pd.DataFrame(df_prep)\n",
    "# df.columns = df_impute.columns \n",
    "\n",
    "# # Build features and target dataframe\n",
    "# features = df.drop([\"target\"], axis=1)\n",
    "# target = pd.DataFrame(df, columns=[\"target\"])\n",
    "\n",
    "KEEP_FEATURES = 5\n",
    "# # fit, we can choose f_regression OR mutual_info_regression, we can test both and see the result\n",
    "importantFeatures = SelectKBest(f_regression, k=KEEP_FEATURES)\n",
    "importantFeatures.fit(features,target)\n",
    "\n",
    "X_new = importantFeatures.transform(features)\n",
    "print(importantFeatures.get_support(indices=True))\n",
    "\n",
    "pd.DataFrame(dict(feature_names= features.columns , scores = importantFeatures.scores_))\\\n",
    "    .sort_values('scores',ascending = False)[:KEEP_FEATURES]\n",
    "# plt.figure()\n",
    "# df_DT.plot.bar()\n",
    "# plt.xlabel('Top '+str(KEEP_FEATURES)+' Predictive Features')\n",
    "# plt.ylabel('Feature Coefficients')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score:  [0.31708349 0.26977677 0.36592821 0.12890328 0.25495498 0.30962938\n",
      " 0.44268113 0.14334469 0.29081643 0.22252838]\n",
      "Accuracy: 0.27(+/- 0.18)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(dt_estimator, X_train, y_train, cv=10)\n",
    "print(\"cross validation score: \", scores)\n",
    "print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Flushing output cache (14 entries)\n"
     ]
    }
   ],
   "source": [
    "%reset out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
