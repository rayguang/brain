{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: training, validation and test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process dataset\n",
    "crime_prep.csv contains many missing data in column 2 (county) and 3 (community). \n",
    "For missing data:\n",
    "1) if it is missing at random, we can drop the data;\n",
    "2) if it is missing not at random (e.g., depend on other variables), we can use imputation to reduce bias.\n",
    "\n",
    "k-fold CV (cross-validation) is used to reduce the risk of overfitting;\n",
    "imputation is used to fill missing data (using mean value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.06269383430480957 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df_prep = pd.read_csv('crime_prep.csv')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#df_prep.shape\n",
    "\n",
    "# Remove non predictive attributes, such as state, county, community, communitynames, fold\n",
    "df_prep = df_prep.drop(['v_cont_0', 'v_cat_0', 'v_cat_1', 'v_cat_2', 'v_cat_3'], axis=1)\n",
    "\n",
    "# Use impute function to fill the missing values (NaN)\n",
    "# Missing value is filled with mean of the column data\n",
    "df_impute = df_prep.copy()\n",
    "impute = Imputer(missing_values=\"NaN\", strategy='mean', axis=0)\n",
    "\n",
    "# Fit the dataframe into imputer\n",
    "impute = impute.fit(df_prep)\n",
    "# Fit the new values into df and transformed\n",
    "df_prep = impute.transform(df_impute)\n",
    "\n",
    "# Convert to dataframe and add columns\n",
    "df = pd.DataFrame(df_prep)\n",
    "df.columns = df_impute.columns \n",
    "#df\n",
    "\n",
    "# Build features and target dataframe\n",
    "features = df.drop([\"target\"], axis=1)\n",
    "target = pd.DataFrame(df, columns=[\"target\"])\n",
    "\n",
    "##############################\n",
    "# Config for feature selection\n",
    "##############################\n",
    "KEEP_FEATURES = 10\n",
    "\n",
    "##############################\n",
    "# Config for CV\n",
    "##############################\n",
    "cv_count = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "1. Filter Method, e.g., pearson correlation\n",
    "2. Wrapper Method\n",
    "    1) backward elimination: feed all the possible features to the model at first and iteratively remove the worst performing features one by one till the overall performance of the model comes in acceptable range.\n",
    "    2) recursive feature elimination: recursively removing attributes and building a model on those attributes that remain.\n",
    "3. Embedded Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance: Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score:  [0.28796166 0.22461444 0.31569316 0.22610981 0.25105404 0.27017045\n",
      " 0.34814943 0.1689841  0.30606431 0.25432409]\n",
      "Accuracy: 0.27(+/- 0.10)\n",
      "           Importance\n",
      "v_cont_55    0.426132\n",
      "v_cont_49    0.077768\n",
      "v_cont_48    0.057545\n",
      "v_cont_8     0.031945\n",
      "v_cont_95    0.021462\n",
      "v_cont_54    0.020235\n",
      "v_cont_97    0.013746\n",
      "v_cont_20    0.012954\n",
      "v_cont_45    0.010059\n",
      "v_cont_58    0.009453\n"
     ]
    }
   ],
   "source": [
    "DT = tree.DecisionTreeRegressor()\n",
    "DT = DT.fit(features, target)\n",
    "\n",
    "DT_predict = DT.predict(features)\n",
    "scores = cross_val_score(DT, features, target, cv=cv_count)\n",
    "print(\"cross validation score: \", scores)\n",
    "print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores.mean(), scores.std()*2))\n",
    "\n",
    "#features_new = zip(features.columns, (SelectKBest(f_regression, k=5).fit_transform(features, target)))\n",
    "importantFeatures = sorted(zip(features.columns, DT.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# fit, we can choose f_regression OR mutual_info_regression, we can test both and see the result\n",
    "importantFeatures[:KEEP_FEATURES]\n",
    "df_DT=pd.DataFrame(DT.feature_importances_, columns = [\"Importance\"], index = features.columns).sort_values(['Importance'], ascending = False)[:KEEP_FEATURES]\n",
    "print(df_DT)\n",
    "# plt.figure()\n",
    "# df_DT.plot.bar()\n",
    "# plt.xlabel('Top '+str(KEEP_FEATURES)+' Predictive Features')\n",
    "# plt.ylabel('Feature Coefficients')\n",
    "# plt.show()\n",
    "\n",
    "#            Importance\n",
    "# v_cont_55    0.426132\n",
    "# v_cont_49    0.077768\n",
    "# v_cont_48    0.057545\n",
    "# v_cont_8     0.031945\n",
    "# v_cont_95    0.021462\n",
    "# v_cont_54    0.020235\n",
    "# v_cont_97    0.013746\n",
    "# v_cont_20    0.012954\n",
    "# v_cont_45    0.010059\n",
    "# v_cont_58    0.009453"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score:  [0.47337836 0.50818785 0.51256966 0.59539048 0.62643043 0.63831034\n",
      " 0.56894194 0.57246909 0.57869827 0.55105908]\n",
      "Accuracy: 0.56(+/- 0.10)\n",
      "            Importance\n",
      "v_cont_55     0.683332\n",
      "v_cont_49     0.238437\n",
      "v_cont_48     0.054646\n",
      "v_cont_8      0.012732\n",
      "v_cont_54     0.007896\n",
      "v_cont_79     0.001070\n",
      "v_cont_106    0.001061\n",
      "v_cont_111    0.000826\n",
      "v_cont_5      0.000000\n",
      "v_cont_86     0.000000\n"
     ]
    }
   ],
   "source": [
    "regr = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\n",
    "regr = regr.fit(features, target)\n",
    "\n",
    "regr_predict = regr.predict(features)\n",
    "scores = cross_val_score(regr, features, target, cv=cv_count)\n",
    "print(\"cross validation score: \", scores)\n",
    "print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores.mean(), scores.std()*2))\n",
    "\n",
    "#features_new = zip(features.columns, (SelectKBest(f_regression, k=5).fit_transform(features, target)))\n",
    "importantFeatures = sorted(zip(features.columns, regr.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# fit, we can choose f_regression OR mutual_info_regression, we can test both and see the result\n",
    "importantFeatures[:KEEP_FEATURES]\n",
    "df_randomforest=pd.DataFrame(regr.feature_importances_, columns = [\"Importance\"], index = features.columns).sort_values(['Importance'], ascending = False)[:KEEP_FEATURES]\n",
    "print(df_randomforest)\n",
    "# plt.figure()\n",
    "# df_DT.plot.bar()\n",
    "# plt.xlabel('Top '+str(KEEP_FEATURES)+' Predictive Features')\n",
    "# plt.ylabel('Feature Coefficients')\n",
    "# plt.show()\n",
    "\n",
    "# cross validation score:  [0.47337836 0.50818785 0.51256966 0.59539048 0.62643043 0.63831034\n",
    "#  0.56894194 0.57246909 0.57869827 0.55105908]\n",
    "# Accuracy: 0.56(+/- 0.10)\n",
    "#             Importance\n",
    "# v_cont_55     0.683332\n",
    "# v_cont_49     0.238437\n",
    "# v_cont_48     0.054646\n",
    "# v_cont_8      0.012732\n",
    "# v_cont_54     0.007896\n",
    "# v_cont_79     0.001070\n",
    "# v_cont_106    0.001061\n",
    "# v_cont_111    0.000826\n",
    "# v_cont_5      0.000000\n",
    "# v_cont_86     0.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # fit, we can choose f_regression OR mutual_info_regression, we can test both and see the result\n",
    "importantFeatures = SelectKBest(f_regression, k=KEEP_FEATURES)\n",
    "importantFeatures.fit(features,target)\n",
    "\n",
    "X_new = importantFeatures.transform(features)\n",
    "#print(importantFeatures.get_support(indices=True))\n",
    "\n",
    "df_SB=pd.DataFrame(dict(feature_names= features.columns , scores = importantFeatures.scores_))\\\n",
    "    .sort_values('scores',ascending = False)[:KEEP_FEATURES]\n",
    "plt.figure()\n",
    "df_SB.plot.bar()\n",
    "plt.xlabel('Top '+str(KEEP_FEATURES)+' Predictive Features')\n",
    "plt.ylabel('Feature Coefficients')\n",
    "plt.show()\n",
    "\n",
    "# \tfeature_names\tscores\n",
    "# 44\tv_cont_49\t2388.618688\n",
    "# 50\tv_cont_55\t2381.983200\n",
    "# 43\tv_cont_48\t1987.057310\n",
    "# 3\tv_cont_8\t1758.772273\n",
    "# 45\tv_cont_50\t1588.379860\n",
    "# 46\tv_cont_51\t1550.531636\n",
    "# 2\tv_cont_7\t1319.686433\n",
    "# 15\tv_cont_20\t990.700975\n",
    "# 17\tv_cont_22\t982.200468\n",
    "# 40\tv_cont_45\t891.494025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: Recursive Feature Elimination (RFE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False  True  True False False False False False False False False\n",
      " False False False False False False False False  True False False  True\n",
      " False False False False False False False  True  True False  True False\n",
      " False  True False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False]\n",
      "[104  66  22 105  84  96  32  26  57 109  74  76  18   3  70  25  44  97\n",
      "  43  17  72  42  65  79 103  59  64  10  36  45  50  98 111   2  52  60\n",
      "  77  49  15  27  28  48  83  33   1  73  82  41  24   9   1   1  93 106\n",
      "  91  90  92  11  12  30  35   4  54   7   6  34  21  20   1  31  78   1\n",
      "  61  19  69  51 110 113  99   1   1 101   1  23  89   1  37 102  29  38\n",
      "   1   5 108  80  53 107  88  46  56  13  71  86  40  39   8  67  94  47\n",
      "  55  81  16  68  87 100 112  58  62  75  95  85  63  14]\n",
      "[('v_cont_49', 1), ('v_cont_55', 1), ('v_cont_56', 1), ('v_cont_73', 1), ('v_cont_76', 1), ('v_cont_84', 1), ('v_cont_85', 1), ('v_cont_87', 1), ('v_cont_90', 1), ('v_cont_95', 1)]\n"
     ]
    }
   ],
   "source": [
    "# create a base classifier used to evaluate a subset of attributes\n",
    "estimator = SVR(kernel='linear')\n",
    "# create the RFE model and select X attributes, X=KEEP_FATURES\n",
    "selector = RFE(estimator, KEEP_FEATURES, step=1)\n",
    "\n",
    "# Without specifing the number of features, RFECV finds the optimal \n",
    "# number of features\n",
    "#selector = RFECV(estimator, step=1, cv=5)\n",
    "\n",
    "# Fit the model\n",
    "selector = selector.fit(features, target)\n",
    "\n",
    "# summarize the selection of the attributes\n",
    "#print(selector.support_)\n",
    "#print(selector.ranking_)\n",
    "rfe_features = sorted(zip(features.columns, selector.ranking_), key=lambda x: x[1], reverse=False)[:KEEP_FEATURES]\n",
    "print(rfe_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "#### Most important features by different methods\n",
    "selectKBest\n",
    "49,55,48,8,50,51,7,20,22,45\n",
    "\n",
    "Decision Tree importance\n",
    "55,49,48,8,95,54,97,20,45,58\n",
    "\n",
    "RFE\n",
    "49,55,56,73,76,84,85,87,90,95\n",
    "\n",
    "We can see that 49/55 ranked highest importance for all the 3 methods, mostly highly correlated with the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction: PCA\n",
    "LDA (\"supervised\"): use information of classes to find new features to maximize its separability\n",
    "PCA (\"unsupervised\"): use variance of each feature to maximize its separability; it actually constructs a new set of features\n",
    "\n",
    "PCA is concerned with covariance of predictor matrix X (input features); in regression, we also need to concern with the covariance of X (features) and y (target). \n",
    "\n",
    "PCR, PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25854019 0.18166128 0.07971167 0.06863376 0.0447857 ]\n",
      "[46.24373896 38.76324226 25.67733016 23.82636609 19.24680277]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca.fit(features)  \n",
    "print(pca.explained_variance_ratio_)  \n",
    "print(pca.singular_values_)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction: SVM\n",
    "*NOTE: GridSearchCV can be used to optimize each of the following models, to make it simple and accelerate the training speed for demo purpose, GridSearchCV is not implemented here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR params: <bound method BaseEstimator.get_params of SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
      "  gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
      "  tol=0.001, verbose=False)>\n",
      "cross validation score:  [0.6105303  0.64428898 0.69607301 0.67623805 0.64421084]\n",
      "Accuracy: 0.65(+/- 0.06)\n",
      "Cross-predicted Accuracy: 0.6554434180226716\n"
     ]
    }
   ],
   "source": [
    "# Default SVR is kernel=rbf\n",
    "# <bound method BaseEstimator.get_params of SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
    "#   gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
    "#   tol=0.001, verbose=False)>\n",
    "svr_base    = svm.SVR()\n",
    "# svr_rbf     = svm.SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
    "# svr_lin     = svm.SVR(kernel='linear', C=100, gamma='auto')\n",
    "# svr_poly    = svm.SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1, coef0=1)\n",
    "print(\"SVR params:\", svr_base.get_params)\n",
    "\n",
    "regressor = svr_base\n",
    "scores_fullfeature = cross_val_score(regressor, features, target, cv=cv_count)\n",
    "print(\"cross validation score: \", scores_fullfeature)\n",
    "print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores_fullfeature.mean(), scores_fullfeature.std()*2))\n",
    "\n",
    "# cross validation score:  [0.6105303  0.64428898 0.69607301 0.67623805 0.64421084]\n",
    "# Accuracy: 0.65(+/- 0.06)\n",
    "\n",
    "# ****************************************************************\n",
    "# Make cross-validation predictions\n",
    "# ****************************************************************\n",
    "predictions = cross_val_predict(regressor, features, target, cv=cv_count)\n",
    "# plt.scatter(target, predictions, edgecolors=(0,0,0))\n",
    "# plt.plot([min(target),max(target)], [min(target), max(target)], 'k--', lw=4)\n",
    "# plt.xlabel(\"Measured\")\n",
    "# plt.ylabel(\"Predicted\")\n",
    "# plt.show()\n",
    "\n",
    "accuracy = metrics.r2_score(target, predictions)\n",
    "print(\"Cross-predicted Accuracy:\", accuracy)\n",
    "\n",
    "# cross validation score:  [0.6105303  0.64428898 0.69607301 0.67623805 0.64421084]\n",
    "# Accuracy: 0.65(+/- 0.06)\n",
    "# Cross-predicted Accuracy: 0.6554434180226716"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction with selected features: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score:  [0.56415762 0.61959577 0.60232492 0.66025589 0.65215808 0.73276236\n",
      " 0.68662424 0.64208606 0.65136553 0.6285674 ]\n",
      "Accuracy: 0.64(+/- 0.09)\n",
      "Cross-predicted Accuracy: 0.6447088310779898\n"
     ]
    }
   ],
   "source": [
    "features_rfe    = features[['v_cont_49','v_cont_55','v_cont_56', 'v_cont_73', 'v_cont_76','v_cont_84','v_cont_85','v_cont_87','v_cont_90','v_cont_95']]\n",
    "features_sb     = features[['v_cont_49','v_cont_55','v_cont_48','v_cont_8','v_cont_50','v_cont_51','v_cont_7','v_cont_20','v_cont_22','v_cont_45']]\n",
    "features_dt     = features[['v_cont_55', 'v_cont_49', 'v_cont_48', 'v_cont_8', 'v_cont_95', 'v_cont_54', 'v_cont_97', 'v_cont_20', 'v_cont_45', 'v_cont_58']]\n",
    "features_forest = features[['v_cont_55', 'v_cont_49', 'v_cont_48', 'v_cont_8','v_cont_54','v_cont_79','v_cont_106','v_cont_111']]\n",
    "target_new = target\n",
    "\n",
    "regressor = svr_base\n",
    "\n",
    "feature_select = features_rfe\n",
    "scores_selectfeature = cross_val_score(regressor, feature_select, target, cv=cv_count)\n",
    "print(\"cross validation score: \", scores_selectfeature)\n",
    "print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores_selectfeature.mean(), scores_selectfeature.std()*2))\n",
    "\n",
    "predictions = cross_val_predict(regressor, feature_select, target, cv=cv_count)\n",
    "accuracy = metrics.r2_score(target, predictions)\n",
    "print(\"Cross-predicted Accuracy:\", accuracy)\n",
    "\n",
    "# cross validation score:  [0.58642208 0.62923829 0.68646175 0.66830287 0.644102  ]\n",
    "# Accuracy: 0.64(+/- 0.07)\n",
    "# Cross-predicted Accuracy: 0.6437637387149937"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion: accuracy with 10 selected features is close to the full feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score:  [0.10245168 0.31361058 0.34538246 0.27211849 0.27847284]\n",
      "Accuracy: 0.26(+/- 0.17)\n",
      "Cross-predicted Accuracy: 0.26242482154656266\n"
     ]
    }
   ],
   "source": [
    "regressor = tree.DecisionTreeRegressor()\n",
    "#clf = clf.fit(features, target) # regression without CV\n",
    "scores_fullfeature = cross_val_score(regressor, features, target, cv=cv_count)\n",
    "print(\"cross validation score: \", scores_fullfeature)\n",
    "print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores_fullfeature.mean(), scores_fullfeature.std()*2))\n",
    "\n",
    "predictions = cross_val_predict(regressor, features, target, cv=cv_count)\n",
    "\n",
    "accuracy = metrics.r2_score(target, predictions)\n",
    "print(\"Cross-predicted Accuracy:\", accuracy)\n",
    "\n",
    "# cross validation score:  [0.10245168 0.31361058 0.34538246 0.27211849 0.27847284]\n",
    "# Accuracy: 0.26(+/- 0.17)\n",
    "# Cross-predicted Accuracy: 0.26242482154656266"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction with selected features: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score:  [0.183659   0.36247151 0.44602598 0.33832722 0.28923339]\n",
      "Accuracy: 0.32(+/- 0.17)\n",
      "Cross-predicted Accuracy: 0.3526285859550219\n"
     ]
    }
   ],
   "source": [
    "feature_select = features_dt\n",
    "scores_selectfeature = cross_val_score(regressor, feature_select, target, cv=cv_count)\n",
    "print(\"cross validation score: \", scores_selectfeature)\n",
    "print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores_selectfeature.mean(), scores_selectfeature.std()*2))\n",
    "\n",
    "predictions = cross_val_predict(regressor, feature_select, target, cv=cv_count)\n",
    "accuracy = metrics.r2_score(target, predictions)\n",
    "print(\"Cross-predicted Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score:  [0.16437023 0.3242882  0.37168    0.2610692  0.23114422]\n",
      "Accuracy: 0.27(+/- 0.14)\n",
      "Cross-predicted Accuracy: 0.25443657597836744\n"
     ]
    }
   ],
   "source": [
    "regressor = tree.DecisionTreeRegressor()\n",
    "scores_fullfeature = cross_val_score(regressor, features, target, cv=cv_count)\n",
    "print(\"cross validation score: \", scores_fullfeature)\n",
    "print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores_fullfeature.mean(), scores_fullfeature.std()*2))\n",
    "\n",
    "predictions = cross_val_predict(regressor, features, target, cv=cv_count)\n",
    "\n",
    "accuracy = metrics.r2_score(target, predictions)\n",
    "print(\"Cross-predicted Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction with selected features: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score:  [0.31719369 0.21411315 0.26871375 0.23131947 0.30823379 0.58348508\n",
      " 0.43398389 0.25831884 0.28190832 0.10537655]\n",
      "Accuracy: 0.30(+/- 0.25)\n",
      "Cross-predicted Accuracy: 0.30407979704820043\n"
     ]
    }
   ],
   "source": [
    "feature_select = features_rfe\n",
    "scores_selectfeature = cross_val_score(regressor, feature_select, target, cv=cv_count)\n",
    "print(\"cross validation score: \", scores_selectfeature)\n",
    "print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores_selectfeature.mean(), scores_selectfeature.std()*2))\n",
    "\n",
    "predictions = cross_val_predict(regressor, feature_select, target, cv=cv_count)\n",
    "accuracy = metrics.r2_score(target, predictions)\n",
    "print(\"Cross-predicted Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score:  [0.47337836 0.50818785 0.51256966 0.59539048 0.62643043 0.63831034\n",
      " 0.56894194 0.57246909 0.57869827 0.55105908]\n",
      "Accuracy: 0.56(+/- 0.10)\n",
      "Cross-predicted Accuracy: 0.5634702626263526\n"
     ]
    }
   ],
   "source": [
    "# depth of tree 2, number of trees 100\n",
    "regressor = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\n",
    "scores_fullfeature = cross_val_score(regressor, features, target, cv=cv_count)\n",
    "print(\"cross validation score: \", scores_fullfeature)\n",
    "print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores_fullfeature.mean(), scores_fullfeature.std()*2))\n",
    "\n",
    "predictions = cross_val_predict(regressor, features, target, cv=cv_count)\n",
    "\n",
    "accuracy = metrics.r2_score(target, predictions)\n",
    "print(\"Cross-predicted Accuracy:\", accuracy)\n",
    "\n",
    "# cross validation score:  [0.47337836 0.50818785 0.51256966 0.59539048 0.62643043 0.63831034\n",
    "#  0.56894194 0.57246909 0.57869827 0.55105908]\n",
    "# Accuracy: 0.56(+/- 0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction with selected features: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score:  [0.54282045 0.57425864 0.57837188 0.65034893 0.65296021 0.70227148\n",
      " 0.63478688 0.61237552 0.62364641 0.55529938]\n",
      "Accuracy: 0.61(+/- 0.09)\n",
      "Cross-predicted Accuracy: 0.6149497533541618\n"
     ]
    }
   ],
   "source": [
    "feature_select = features_forest\n",
    "scores_selectfeature = cross_val_score(regressor, feature_select, target, cv=cv_count)\n",
    "print(\"cross validation score: \", scores_selectfeature)\n",
    "print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores_selectfeature.mean(), scores_selectfeature.std()*2))\n",
    "\n",
    "predictions = cross_val_predict(regressor, feature_select, target, cv=cv_count)\n",
    "accuracy = metrics.r2_score(target, predictions)\n",
    "print(\"Cross-predicted Accuracy:\", accuracy)\n",
    "\n",
    "# cross validation score:  [0.54282045 0.57425864 0.57837188 0.65034893 0.65296021 0.70227148\n",
    "#  0.63478688 0.61237552 0.62364641 0.55529938]\n",
    "# Accuracy: 0.61(+/- 0.09)\n",
    "# Cross-predicted Accuracy: 0.6149497533541618"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (5,1) into shape (5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3ac3c1b76b87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b^'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RandomForestRegressor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ys'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LinearRegression'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mereg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r*'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'VotingRegressor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'both'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predicted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/voting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m    475\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"estimators_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         return np.average(self._predict(X), axis=1,\n\u001b[0m\u001b[1;32m    477\u001b[0m                           weights=self._weights_not_none)\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/voting.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (5,1) into shape (5)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training classifier\n",
    "reg1 = GradientBoostingRegressor(random_state=1, n_estimators=10)\n",
    "reg2 = RandomForestRegressor(random_state=1, n_estimators=10)\n",
    "reg3 = LinearRegression()\n",
    "ereg = VotingRegressor(estimators=[('gb', reg1), ('rf', reg2), ('lr', reg3)])\n",
    "reg1.fit(features, target)\n",
    "reg2.fit(features, target)\n",
    "reg3.fit(features, target)\n",
    "ereg.fit(features, target)\n",
    "\n",
    "xt = features[:5]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(reg1.predict(xt), 'gd', label='GradientBoostingRegressor')\n",
    "plt.plot(reg2.predict(xt), 'b^', label='RandomForestRegressor')\n",
    "plt.plot(reg3.predict(xt), 'ys', label='LinearRegression')\n",
    "plt.plot(ereg.predict(xt), 'r*', label='VotingRegressor')\n",
    "plt.tick_params(axis='x', which='both', bottom=False, top=False,labelbottom=False)\n",
    "plt.ylabel('predicted')\n",
    "plt.xlabel('training samples')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title('Comparison of individual predictions with averaged')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   v_cont_5  v_cont_6  v_cont_7  v_cont_8  v_cont_9  v_cont_10  v_cont_11  \\\n",
      "0      0.19      0.33      0.02      0.90      0.12       0.17       0.34   \n",
      "1      0.00      0.16      0.12      0.74      0.45       0.07       0.26   \n",
      "2      0.00      0.42      0.49      0.56      0.17       0.04       0.39   \n",
      "3      0.04      0.77      1.00      0.08      0.12       0.10       0.51   \n",
      "4      0.01      0.55      0.02      0.95      0.09       0.05       0.38   \n",
      "\n",
      "   v_cont_12  v_cont_13  v_cont_14     ...      v_cont_117  v_cont_118  \\\n",
      "0       0.47       0.29       0.32     ...        0.290000        0.12   \n",
      "1       0.59       0.35       0.27     ...        0.305987        0.02   \n",
      "2       0.47       0.28       0.32     ...        0.305987        0.01   \n",
      "3       0.50       0.34       0.21     ...        0.305987        0.02   \n",
      "4       0.38       0.23       0.36     ...        0.305987        0.04   \n",
      "\n",
      "   v_cont_119  v_cont_120  v_cont_121  v_cont_122  v_cont_123  v_cont_124  \\\n",
      "0        0.26        0.20    0.060000    0.040000    0.900000    0.500000   \n",
      "1        0.12        0.45    0.163103    0.076708    0.698589    0.440439   \n",
      "2        0.21        0.02    0.163103    0.076708    0.698589    0.440439   \n",
      "3        0.39        0.28    0.163103    0.076708    0.698589    0.440439   \n",
      "4        0.09        0.02    0.163103    0.076708    0.698589    0.440439   \n",
      "\n",
      "   v_cont_125  v_cont_126  \n",
      "0        0.32    0.140000  \n",
      "1        0.00    0.195078  \n",
      "2        0.00    0.195078  \n",
      "3        0.00    0.195078  \n",
      "4        0.00    0.195078  \n",
      "\n",
      "[5 rows x 122 columns]\n"
     ]
    }
   ],
   "source": [
    "print(xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "* learning_rate: step size shrinkage used to prevent overfitting. Range is [0,1]\n",
    "* max_depth: determines how deeply each tree is allowed to grow during any boosting round.\n",
    "* subsample: percentage of samples used per tree. Low value can lead to underfitting.\n",
    "* colsample_bytree: percentage of features used per tree. High value can lead to overfitting.\n",
    "* n_estimators: number of trees you want to build.\n",
    "* objective: determines the loss function to be used like reg:linear for regression problems, reg:logistic for classification problems with only decision, binary:logistic for classification problems with probability.\n",
    "\n",
    "* gamma: controls whether a given node will split based on the expected reduction in loss after the split. A higher value leads to fewer splits. Supported only for tree-based learners.\n",
    "* alpha: L1 regularization on leaf weights. A large value leads to more regularization.\n",
    "* lambda: L2 regularization on leaf weights and is smoother than L1 regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:32:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "RMSE: 0.183738\n",
      "[11:32:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:32:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:32:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.324284</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.324692</td>\n",
       "      <td>0.004207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.301147</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.302126</td>\n",
       "      <td>0.004023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.280715</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.282281</td>\n",
       "      <td>0.004137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.262875</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.264892</td>\n",
       "      <td>0.004229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.246492</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.249246</td>\n",
       "      <td>0.003949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0         0.324284        0.001468        0.324692       0.004207\n",
       "1         0.301147        0.001043        0.302126       0.004023\n",
       "2         0.280715        0.000722        0.282281       0.004137\n",
       "3         0.262875        0.000379        0.264892       0.004229\n",
       "4         0.246492        0.000104        0.249246       0.003949"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataset to dmatrix, which xgboost supports for high performance\n",
    "data_dmatrix = xgb.DMatrix(data=features,label=target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=123)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "\n",
    "\n",
    "cv_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
